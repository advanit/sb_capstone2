{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sai: spooky author identification\n",
    "## analysis 3: TF-IDF Vectorizer\n",
    "\n",
    "## strategy\n",
    "This will apply TF-IDF vectorizer with the following classifiers:\n",
    "\n",
    "* Multinomial Naive Bayes \n",
    "* Logistic Regression\n",
    "* Random Forest\n",
    "\n",
    "The same practices done with CountVectorizer, will occur here as well.  Therefore, it will create about 6 experiments:\n",
    "\n",
    "* Split, vectorize TF-IDF + MultinomialNB()\n",
    "* Vectorize TF-IDF, split, MultinomialNB()\n",
    "* Split, vectorize TF-IDF + LogisticRegression()\n",
    "* Vectorize TF-IDF, split, LogisticRegression()\n",
    "* Split, vectorize TF-IDF + RandomForestClassifier()\n",
    "* Vectorize TF-IDF, split, RandomForestClassifier()\n",
    "\n",
    "Runtime will be long.  RandomizedSearchCV will be used for all to save time.\n",
    "\n",
    "## code\n",
    "### preliminaries\n",
    "This is the 'de facto' run, where it loads libraries and necessary modules to perform the analysis.  Afterwards, it will read a simple csv file into a dataframe called 'texts.'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# sklearn\n",
    "from sklearn.cross_validation import train_test_split             # cross-validation\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer      # vectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB                     # classifier\n",
    "from sklearn.linear_model import LogisticRegression               # classifier\n",
    "from sklearn.ensemble import RandomForestClassifier               # classifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier                 # classifier\n",
    "from sklearn.model_selection import GridSearchCV                  # parameter tuning\n",
    "from sklearn.model_selection import RandomizedSearchCV            # parameter tuning\n",
    "from sklearn.pipeline import Pipeline                             # pipeline\n",
    "from sklearn import metrics                                       # metrics\n",
    "\n",
    "# other modules\n",
    "from stop_words import get_stop_words\n",
    "from scipy.stats import randint as sp_randint\n",
    "import string\n",
    "from pprint import pprint\n",
    "\n",
    "# Read training texts: texts\n",
    "texts = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize + Naive Bayes = Experiment 1 (Split / Vectorize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Feature Selection\n",
    "X = texts.text\n",
    "y = texts.author\n",
    "\n",
    "# Train Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pipeline\n",
    "pipeline_A1 = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('nb', MultinomialNB()),\n",
    "])\n",
    "\n",
    "# parameters\n",
    "parameters_A1 = dict(\n",
    "    tfidf__ngram_range = [(1,1), (1,2), (1,3)],\n",
    "    tfidf__max_df = (0.5, 0.75, 1.0),\n",
    "    nb__alpha = [0.05, 0.1, 1.0, 2.0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cv=5 academically proven as best fold, kept n_jobs (jobs running parallel)= 1, output time\n",
    "rand_search_A1 = RandomizedSearchCV(pipeline_A1, \n",
    "                           parameters_A1, \n",
    "                           n_jobs=1, \n",
    "                           cv=5\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['tfidf', 'nb']\n",
      "parameters:\n",
      "{'nb__alpha': [0.05, 0.1, 1.0, 2.0],\n",
      " 'tfidf__max_df': (0.5, 0.75, 1.0),\n",
      " 'tfidf__ngram_range': [(...), (...), (...)]}\n",
      "CPU times: user 2min 42s, sys: 5.28 s, total: 2min 47s\n",
      "Wall time: 2min 48s\n",
      "Best score: 0.845\n",
      "Best parameters set:\n",
      "\tnb__alpha: 0.05\n",
      "\ttfidf__max_df: 0.5\n",
      "\ttfidf__ngram_range: (1, 2)\n"
     ]
    }
   ],
   "source": [
    "# fit model for best parameters\n",
    "print(\"Performing grid search...\")\n",
    "print(\"pipeline:\", [name for name, _ in pipeline_A1.steps])\n",
    "print(\"parameters:\")\n",
    "pprint(parameters_A1, depth=2)\n",
    "\n",
    "%time rand_search_A1.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best score: %0.3f\" % rand_search_A1.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "\n",
    "best_parameters = rand_search_A1.best_estimator_.get_params()\n",
    "\n",
    "for param_name in sorted(parameters_A1.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate estimator\n",
    "stop_word = get_stop_words('english')\n",
    "vect_A1 = TfidfVectorizer(binary=True, ngram_range=(1,2), stop_words=stop_word, max_df=0.75)\n",
    "nb_A1 = MultinomialNB(alpha=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit & transform with vectorizer\n",
    "X_train_dtm = vect_A1.fit_transform(X_train)\n",
    "\n",
    "# fit with classifer\n",
    "nb_A1.fit(X_train_dtm, y_train)\n",
    "\n",
    "# predict with classifier\n",
    "y_pred_train = nb_A1.predict(X_train_dtm)\n",
    "\n",
    "# transform with vectorizer, then predict with classifier\n",
    "X_test_dtm = vect_A1.transform(X_test)\n",
    "y_pred_test = nb_A1.predict(X_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.998637973304\n"
     ]
    }
   ],
   "source": [
    "print(metrics.accuracy_score(y_pred_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.834729315628\n"
     ]
    }
   ],
   "source": [
    "print(metrics.accuracy_score(y_pred_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5922    9    5]\n",
      " [   2 4217    3]\n",
      " [   1    0 4525]]\n"
     ]
    }
   ],
   "source": [
    "print(metrics.confusion_matrix(y_pred_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1679  192  183]\n",
      " [ 128 1136   57]\n",
      " [ 168   81 1271]]\n"
     ]
    }
   ],
   "source": [
    "print(metrics.confusion_matrix(y_pred_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        EAP       1.00      1.00      1.00      5936\n",
      "        HPL       1.00      1.00      1.00      4222\n",
      "        MWS       1.00      1.00      1.00      4526\n",
      "\n",
      "avg / total       1.00      1.00      1.00     14684\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_pred_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        EAP       0.85      0.82      0.83      2054\n",
      "        HPL       0.81      0.86      0.83      1321\n",
      "        MWS       0.84      0.84      0.84      1520\n",
      "\n",
      "avg / total       0.84      0.83      0.83      4895\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_pred_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "181713 (3, 181713)\n"
     ]
    }
   ],
   "source": [
    "# store vocabulary of X_train\n",
    "X_train_tokens = vect_A1.get_feature_names()\n",
    "\n",
    "# rows represent classes\n",
    "print(len(X_train_tokens), nb_A1.feature_count_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# number of times each token appears across all EAP messages\n",
    "EAP_token_count = nb_A1.feature_count_[0,:]\n",
    "\n",
    "# number of times each token appears across all HPL messages\n",
    "HPL_token_count = nb_A1.feature_count_[1,:]\n",
    "\n",
    "# number of times each token appears across all MWS messages\n",
    "MWS_token_count = nb_A1.feature_count_[2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EAP</th>\n",
       "      <th>HPL</th>\n",
       "      <th>MWS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>entirely covered</th>\n",
       "      <td>0.184236</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rummer</th>\n",
       "      <td>0.244745</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pelf centuried</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.232970</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>felix brother</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.306676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>retain</th>\n",
       "      <td>0.557495</td>\n",
       "      <td>0.449432</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       EAP       HPL       MWS\n",
       "token                                         \n",
       "entirely covered  0.184236  0.000000  0.000000\n",
       "rummer            0.244745  0.000000  0.000000\n",
       "pelf centuried    0.000000  0.232970  0.000000\n",
       "felix brother     0.000000  0.000000  0.306676\n",
       "retain            0.557495  0.449432  0.000000"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DataFrame of tokens with their separate ham and spam counts\n",
    "tokens = pd.DataFrame({'token':X_train_tokens, 'EAP':EAP_token_count, 'HPL':HPL_token_count, 'MWS':MWS_token_count}).set_index('token')\n",
    "tokens.sample(5, random_state=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# avoid dividing by 0 (class imbalance)\n",
    "tokens['EAP'] = tokens.EAP + 1\n",
    "tokens['HPL'] = tokens.HPL + 1\n",
    "tokens['MWS'] = tokens.MWS + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert into frequencies \n",
    "tokens['EAP'] = tokens.EAP / nb_A1.class_count_[0]\n",
    "tokens['HPL'] = tokens.HPL / nb_A1.class_count_[1]\n",
    "tokens['MWS'] = tokens.MWS / nb_A1.class_count_[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token\n",
      "upon       0.009923\n",
      "one        0.006662\n",
      "now        0.005922\n",
      "said       0.005776\n",
      "will       0.005269\n",
      "say        0.004377\n",
      "however    0.004355\n",
      "little     0.003919\n",
      "well       0.003866\n",
      "made       0.003659\n",
      "Name: EAP, dtype: float64 \n",
      "\n",
      "token\n",
      "one       0.007390\n",
      "old       0.006728\n",
      "man       0.005220\n",
      "now       0.005176\n",
      "night     0.005148\n",
      "seemed    0.005108\n",
      "though    0.004830\n",
      "like      0.004737\n",
      "saw       0.004720\n",
      "came      0.004646\n",
      "Name: HPL, dtype: float64 \n",
      "\n",
      "token\n",
      "will       0.006415\n",
      "raymond    0.006166\n",
      "one        0.005755\n",
      "life       0.005631\n",
      "now        0.005615\n",
      "love       0.005389\n",
      "yet        0.005303\n",
      "heart      0.004890\n",
      "perdita    0.004564\n",
      "us         0.004437\n",
      "Name: MWS, dtype: float64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# examine DataFrame by author\n",
    "for name in tokens.columns:\n",
    "    print(tokens[name].nlargest(10),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize + Naive Bayes = Experiment 2 (Vectorize / Split)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['tfidf', 'nb']\n",
      "parameters:\n",
      "{'nb__alpha': [0.05, 0.1, 1.0, 2.0],\n",
      " 'tfidf__max_df': (0.5, 0.75, 1.0),\n",
      " 'tfidf__ngram_range': [(...), (...), (...)]}\n",
      "CPU times: user 3min 19s, sys: 5.9 s, total: 3min 25s\n",
      "Wall time: 3min 25s\n",
      "Best score: 0.854\n",
      "Best parameters set:\n",
      "\tnb__alpha: 0.1\n",
      "\ttfidf__max_df: 1.0\n",
      "\ttfidf__ngram_range: (1, 2)\n"
     ]
    }
   ],
   "source": [
    "# fit model for best parameters\n",
    "print(\"Performing grid search...\")\n",
    "print(\"pipeline:\", [name for name, _ in pipeline_A1.steps])\n",
    "print(\"parameters:\")\n",
    "pprint(parameters_A1, depth=2)\n",
    "\n",
    "%time rand_search_A1.fit(X, y)\n",
    "\n",
    "print(\"Best score: %0.3f\" % rand_search_A1.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "\n",
    "best_parameters = rand_search_A1.best_estimator_.get_params()\n",
    "\n",
    "for param_name in sorted(parameters_A1.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# instantiate estimator\n",
    "vect_A2 = TfidfVectorizer(binary=True, ngram_range=(1,2), stop_words=stop_word, max_df=1.0)\n",
    "nb_A2 = MultinomialNB(alpha=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit with vectorizer\n",
    "vect_A2.fit(X)\n",
    "\n",
    "# transform with vectorizer\n",
    "X_train_dtm = vect_A2.transform(X_train)\n",
    "\n",
    "# fit with classifer\n",
    "nb_A2.fit(X_train_dtm, y_train)\n",
    "\n",
    "# predict with classifier\n",
    "y_pred_train = nb_A2.predict(X_train_dtm)\n",
    "\n",
    "# transform with vectorizer, then predict with classifier\n",
    "X_test_dtm = vect_A2.transform(X_test)\n",
    "y_pred_test = nb_A2.predict(X_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.998501770635\n"
     ]
    }
   ],
   "source": [
    "print(metrics.accuracy_score(y_pred_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.841675178754\n"
     ]
    }
   ],
   "source": [
    "print(metrics.accuracy_score(y_pred_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5922    9    6]\n",
      " [   2 4216    3]\n",
      " [   1    1 4524]]\n"
     ]
    }
   ],
   "source": [
    "print(metrics.confusion_matrix(y_pred_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1689  185  165]\n",
      " [ 113 1136   51]\n",
      " [ 173   88 1295]]\n"
     ]
    }
   ],
   "source": [
    "print(metrics.confusion_matrix(y_pred_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        EAP       1.00      1.00      1.00      5937\n",
      "        HPL       1.00      1.00      1.00      4221\n",
      "        MWS       1.00      1.00      1.00      4526\n",
      "\n",
      "avg / total       1.00      1.00      1.00     14684\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_pred_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        EAP       0.86      0.83      0.84      2039\n",
      "        HPL       0.81      0.87      0.84      1300\n",
      "        MWS       0.86      0.83      0.84      1556\n",
      "\n",
      "avg / total       0.84      0.84      0.84      4895\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_pred_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "234396 (3, 234396)\n"
     ]
    }
   ],
   "source": [
    "# store vocabulary of X_train\n",
    "X_train_tokens = vect_A2.get_feature_names()\n",
    "\n",
    "# rows represent classes\n",
    "print(len(X_train_tokens), nb_A2.feature_count_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# number of times each token appears across all EAP messages\n",
    "EAP_token_count = nb_A2.feature_count_[0,:]\n",
    "\n",
    "# number of times each token appears across all HPL messages\n",
    "HPL_token_count = nb_A2.feature_count_[1,:]\n",
    "\n",
    "# number of times each token appears across all MWS messages\n",
    "MWS_token_count = nb_A2.feature_count_[2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DataFrame of tokens with their separate ham and spam counts\n",
    "tokens = pd.DataFrame({'token':X_train_tokens, 'EAP':EAP_token_count, 'HPL':HPL_token_count, 'MWS':MWS_token_count}).set_index('token')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# avoid dividing by 0 (class imbalance)\n",
    "tokens['EAP'] = tokens.EAP + 1\n",
    "tokens['HPL'] = tokens.HPL + 1\n",
    "tokens['MWS'] = tokens.MWS + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert into frequencies \n",
    "tokens['EAP'] = tokens.EAP / nb_A1.class_count_[0]\n",
    "tokens['HPL'] = tokens.HPL / nb_A1.class_count_[1]\n",
    "tokens['MWS'] = tokens.MWS / nb_A1.class_count_[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token\n",
      "upon       0.009757\n",
      "one        0.006578\n",
      "now        0.005828\n",
      "said       0.005638\n",
      "will       0.005171\n",
      "say        0.004312\n",
      "however    0.004254\n",
      "little     0.003846\n",
      "well       0.003798\n",
      "found      0.003588\n",
      "Name: EAP, dtype: float64 \n",
      "\n",
      "token\n",
      "one       0.007299\n",
      "old       0.006582\n",
      "man       0.005133\n",
      "now       0.005093\n",
      "night     0.005036\n",
      "seemed    0.004988\n",
      "though    0.004724\n",
      "saw       0.004658\n",
      "like      0.004654\n",
      "came      0.004572\n",
      "Name: HPL, dtype: float64 \n",
      "\n",
      "token\n",
      "will       0.006296\n",
      "raymond    0.006035\n",
      "one        0.005683\n",
      "life       0.005552\n",
      "now        0.005526\n",
      "love       0.005292\n",
      "yet        0.005195\n",
      "heart      0.004812\n",
      "perdita    0.004476\n",
      "us         0.004365\n",
      "Name: MWS, dtype: float64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# examine DataFrame by author\n",
    "for name in tokens.columns:\n",
    "    print(tokens[name].nlargest(10),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize + Logistic Regression = Experiment 1 (Split / Vectorize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pipeline\n",
    "pipeline_B1 = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('log_reg', LogisticRegression()),\n",
    "])\n",
    "\n",
    "# parameters\n",
    "parameters_B1 = dict(\n",
    "    tfidf__ngram_range = [(1,1), (1,2), (1,3)],\n",
    "    tfidf__max_df = (0.5, 0.75, 1.0),\n",
    "    log_reg__C = [0.05, 0.1, 1.0, 2.0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cv=5 academically proven as best fold, kept n_jobs (jobs running parallel)= 1, output time\n",
    "rand_search_B1 = RandomizedSearchCV(pipeline_B1, \n",
    "                           parameters_B1, \n",
    "                           n_jobs=1, \n",
    "                           cv=5\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['tfidf', 'log_reg']\n",
      "parameters:\n",
      "{'log_reg__C': [0.05, 0.1, 1.0, 2.0],\n",
      " 'tfidf__max_df': (0.5, 0.75, 1.0),\n",
      " 'tfidf__ngram_range': [(...), (...), (...)]}\n",
      "CPU times: user 3min 58s, sys: 32 s, total: 4min 30s\n",
      "Wall time: 2min 56s\n",
      "Best score: 0.806\n",
      "Best parameters set:\n",
      "\tlog_reg__C: 2.0\n",
      "\ttfidf__max_df: 1.0\n",
      "\ttfidf__ngram_range: (1, 1)\n"
     ]
    }
   ],
   "source": [
    "# fit model for best parameters\n",
    "print(\"Performing grid search...\")\n",
    "print(\"pipeline:\", [name for name, _ in pipeline_B1.steps])\n",
    "print(\"parameters:\")\n",
    "pprint(parameters_B1, depth=2)\n",
    "\n",
    "%time rand_search_B1.fit(X, y)\n",
    "\n",
    "print(\"Best score: %0.3f\" % rand_search_B1.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "\n",
    "best_parameters = rand_search_B1.best_estimator_.get_params()\n",
    "\n",
    "for param_name in sorted(parameters_B1.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# instantiate estimator\n",
    "vect_B1 = TfidfVectorizer(binary=True, ngram_range=(1,1), stop_words=stop_word, max_df=1.0)\n",
    "logreg_B1 = LogisticRegression(C=2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit & transform with vectorizer\n",
    "X_train_dtm = vect_B1.fit_transform(X_train)\n",
    "\n",
    "# fit with classifer\n",
    "logreg_B1.fit(X_train_dtm, y_train)\n",
    "\n",
    "# predict with classifier\n",
    "y_pred_train = logreg_B1.predict(X_train_dtm)\n",
    "\n",
    "# transform with vectorizer, then predict with classifier\n",
    "X_test_dtm = vect_B1.transform(X_test)\n",
    "y_pred_test = logreg_B1.predict(X_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.944701716154\n"
     ]
    }
   ],
   "source": [
    "print(metrics.accuracy_score(y_pred_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.81695607763\n"
     ]
    }
   ],
   "source": [
    "print(metrics.accuracy_score(y_pred_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5700  210  228]\n",
      " [  97 3947   80]\n",
      " [ 128   69 4225]]\n"
     ]
    }
   ],
   "source": [
    "print(metrics.confusion_matrix(y_pred_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1708  221  254]\n",
      " [ 127 1102   68]\n",
      " [ 140   86 1189]]\n"
     ]
    }
   ],
   "source": [
    "print(metrics.confusion_matrix(y_pred_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        EAP       0.96      0.93      0.95      6138\n",
      "        HPL       0.93      0.96      0.95      4124\n",
      "        MWS       0.93      0.96      0.94      4422\n",
      "\n",
      "avg / total       0.95      0.94      0.94     14684\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_pred_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        EAP       0.86      0.78      0.82      2183\n",
      "        HPL       0.78      0.85      0.81      1297\n",
      "        MWS       0.79      0.84      0.81      1415\n",
      "\n",
      "avg / total       0.82      0.82      0.82      4895\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_pred_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get feature names\n",
    "X_train_tokens = vect_B1.get_feature_names()\n",
    "\n",
    "# Calculate coefficient into odd, calculate odd into probability\n",
    "log_reg_prob=np.exp(logreg_B1.coef_)/(np.exp(logreg_B1.coef_)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# coefficients each token appears across all classes\n",
    "EAP_token_prob = log_reg_prob[0,:]\n",
    "HPL_token_prob = log_reg_prob[1,:]\n",
    "MWS_token_prob = log_reg_prob[2,:]\n",
    "\n",
    "# number of times each token appears\n",
    "EAP_token_coef = logreg_B1.coef_[0,:]\n",
    "HPL_token_coef = logreg_B1.coef_[1,:]\n",
    "MWS_token_coef = logreg_B1.coef_[2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Coefficient DataFrame\n",
    "coefs = pd.DataFrame({'token':X_train_tokens, \n",
    "                       'EAP':EAP_token_coef, \n",
    "                       'HPL':HPL_token_coef, \n",
    "                       'MWS':MWS_token_coef}).set_index('token')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token\n",
      "upon          6.562724\n",
      "madame        3.764638\n",
      "however       3.619355\n",
      "dupin         3.466446\n",
      "matter        3.426787\n",
      "lady          3.340734\n",
      "character     3.201394\n",
      "altogether    3.184059\n",
      "mr            3.156012\n",
      "although      3.146067\n",
      "Name: EAP, dtype: float64 \n",
      "\n",
      "token\n",
      "though       6.083431\n",
      "west         4.823636\n",
      "street       4.567506\n",
      "later        4.501265\n",
      "gilman       4.205996\n",
      "despite      4.125355\n",
      "old          3.986580\n",
      "innsmouth    3.831145\n",
      "men          3.678563\n",
      "whilst       3.507929\n",
      "Name: HPL, dtype: float64 \n",
      "\n",
      "token\n",
      "raymond    8.191651\n",
      "perdita    6.080660\n",
      "adrian     5.910498\n",
      "towards    5.586380\n",
      "love       4.787638\n",
      "idris      4.634267\n",
      "plague     4.205655\n",
      "misery     4.176011\n",
      "sister     4.062894\n",
      "cottage    3.972599\n",
      "Name: MWS, dtype: float64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# examine DataFrame by author\n",
    "for name in coefs.columns:\n",
    "    print(coefs[name].nlargest(10),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Probability DataFrame\n",
    "probs = pd.DataFrame({'token':X_train_tokens, \n",
    "                       'EAP':EAP_token_prob, \n",
    "                       'HPL':HPL_token_prob, \n",
    "                       'MWS':MWS_token_prob}).set_index('token')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token\n",
      "upon          0.998590\n",
      "madame        0.977349\n",
      "however       0.973900\n",
      "dupin         0.969718\n",
      "matter        0.968531\n",
      "lady          0.965800\n",
      "character     0.960887\n",
      "altogether    0.960230\n",
      "mr            0.959145\n",
      "although      0.958753\n",
      "Name: EAP, dtype: float64 \n",
      "\n",
      "token\n",
      "though       0.997725\n",
      "west         0.992027\n",
      "street       0.989723\n",
      "later        0.989027\n",
      "gilman       0.985313\n",
      "despite      0.984099\n",
      "old          0.981775\n",
      "innsmouth    0.978775\n",
      "men          0.975363\n",
      "whilst       0.970913\n",
      "Name: HPL, dtype: float64 \n",
      "\n",
      "token\n",
      "raymond    0.999723\n",
      "perdita    0.997719\n",
      "adrian     0.997296\n",
      "towards    0.996265\n",
      "love       0.991737\n",
      "idris      0.990380\n",
      "plague     0.985308\n",
      "misery     0.984873\n",
      "sister     0.983092\n",
      "cottage    0.981523\n",
      "Name: MWS, dtype: float64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# examine DataFrame by author\n",
    "for name in probs.columns:\n",
    "    print(probs[name].nlargest(10),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize + Logistic Regression = Experiment 2 (Vectorize / Split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['tfidf', 'log_reg']\n",
      "parameters:\n",
      "{'log_reg__C': [0.05, 0.1, 1.0, 2.0],\n",
      " 'tfidf__max_df': (0.5, 0.75, 1.0),\n",
      " 'tfidf__ngram_range': [(...), (...), (...)]}\n",
      "CPU times: user 4min 50s, sys: 39.4 s, total: 5min 30s\n",
      "Wall time: 3min 39s\n",
      "Best score: 0.821\n",
      "Best parameters set:\n",
      "\tlog_reg__C: 2.0\n",
      "\ttfidf__max_df: 0.75\n",
      "\ttfidf__ngram_range: (1, 1)\n"
     ]
    }
   ],
   "source": [
    "# fit model for best parameters\n",
    "print(\"Performing grid search...\")\n",
    "print(\"pipeline:\", [name for name, _ in pipeline_B1.steps])\n",
    "print(\"parameters:\")\n",
    "pprint(parameters_B1, depth=2)\n",
    "\n",
    "%time rand_search_B1.fit(X, y)\n",
    "\n",
    "print(\"Best score: %0.3f\" % rand_search_B1.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "\n",
    "best_parameters = rand_search_B1.best_estimator_.get_params()\n",
    "\n",
    "for param_name in sorted(parameters_B1.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# instantiate estimator\n",
    "vect_B2 = TfidfVectorizer(binary=True, ngram_range=(1,1), stop_words=None, max_df=0.5)\n",
    "logreg_B2 = LogisticRegression(C=2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit with vectorizer\n",
    "vect_B2.fit(X)\n",
    "\n",
    "# transform with vectorizer\n",
    "X_train_dtm = vect_B2.transform(X_train)\n",
    "\n",
    "# fit with classifer\n",
    "logreg_B2.fit(X_train_dtm, y_train)\n",
    "\n",
    "# predict with classifier\n",
    "y_pred_train = logreg_B2.predict(X_train_dtm)\n",
    "\n",
    "# transform with vectorizer, then predict with classifier\n",
    "X_test_dtm = vect_B2.transform(X_test)\n",
    "y_pred_test = logreg_B2.predict(X_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.937278670662\n"
     ]
    }
   ],
   "source": [
    "print(metrics.accuracy_score(y_pred_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.823493360572\n"
     ]
    }
   ],
   "source": [
    "print(metrics.accuracy_score(y_pred_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5638  201  248]\n",
      " [ 108 3940  100]\n",
      " [ 179   85 4185]]\n"
     ]
    }
   ],
   "source": [
    "print(metrics.confusion_matrix(y_pred_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1696  211  222]\n",
      " [ 142 1128   82]\n",
      " [ 137   70 1207]]\n"
     ]
    }
   ],
   "source": [
    "print(metrics.confusion_matrix(y_pred_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        EAP       0.95      0.93      0.94      6087\n",
      "        HPL       0.93      0.95      0.94      4148\n",
      "        MWS       0.92      0.94      0.93      4449\n",
      "\n",
      "avg / total       0.94      0.94      0.94     14684\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_pred_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        EAP       0.86      0.80      0.83      2129\n",
      "        HPL       0.80      0.83      0.82      1352\n",
      "        MWS       0.80      0.85      0.83      1414\n",
      "\n",
      "avg / total       0.83      0.82      0.82      4895\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_pred_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get feature names\n",
    "X_train_tokens = vect_B2.get_feature_names()\n",
    "\n",
    "# Calculate coefficient into odd, calculate odd into probability\n",
    "log_reg_prob=np.exp(logreg_B2.coef_)/(np.exp(logreg_B2.coef_)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# coefficients each token appears across all classes\n",
    "EAP_token_prob = log_reg_prob[0,:]\n",
    "HPL_token_prob = log_reg_prob[1,:]\n",
    "MWS_token_prob = log_reg_prob[2,:]\n",
    "\n",
    "# number of times each token appears\n",
    "EAP_token_coef = logreg_B2.coef_[0,:]\n",
    "HPL_token_coef = logreg_B2.coef_[1,:]\n",
    "MWS_token_coef = logreg_B2.coef_[2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Coefficient DataFrame\n",
    "coefs = pd.DataFrame({'token':X_train_tokens, \n",
    "                       'EAP':EAP_token_coef, \n",
    "                       'HPL':HPL_token_coef, \n",
    "                       'MWS':MWS_token_coef}).set_index('token')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token\n",
      "upon         6.746061\n",
      "is           3.889144\n",
      "however      3.838754\n",
      "madame       3.821593\n",
      "lady         3.658483\n",
      "dupin        3.278529\n",
      "minutes      3.242017\n",
      "although     3.234435\n",
      "marie        3.210714\n",
      "character    3.124110\n",
      "Name: EAP, dtype: float64 \n",
      "\n",
      "token\n",
      "though       6.164898\n",
      "west         4.582290\n",
      "later        4.435798\n",
      "street       4.219803\n",
      "despite      4.102376\n",
      "old          4.017074\n",
      "uncle        3.968330\n",
      "gilman       3.936558\n",
      "men          3.906260\n",
      "innsmouth    3.705354\n",
      "Name: HPL, dtype: float64 \n",
      "\n",
      "token\n",
      "raymond    8.194954\n",
      "adrian     5.920245\n",
      "perdita    5.732935\n",
      "her        5.660064\n",
      "towards    5.109025\n",
      "love       4.825883\n",
      "my         4.687107\n",
      "idris      4.593774\n",
      "she        4.478862\n",
      "plague     4.407684\n",
      "Name: MWS, dtype: float64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# examine DataFrame by author\n",
    "for name in coefs.columns:\n",
    "    print(coefs[name].nlargest(10),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Probability DataFrame\n",
    "probs = pd.DataFrame({'token':X_train_tokens, \n",
    "                       'EAP':EAP_token_prob, \n",
    "                       'HPL':HPL_token_prob, \n",
    "                       'MWS':MWS_token_prob}).set_index('token')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token\n",
      "upon         0.998826\n",
      "is           0.979947\n",
      "however      0.978933\n",
      "madame       0.978576\n",
      "lady         0.974876\n",
      "dupin        0.963685\n",
      "minutes      0.962385\n",
      "although     0.962110\n",
      "marie        0.961235\n",
      "character    0.957876\n",
      "Name: EAP, dtype: float64 \n",
      "\n",
      "token\n",
      "though       0.997902\n",
      "west         0.989872\n",
      "later        0.988293\n",
      "street       0.985511\n",
      "despite      0.983736\n",
      "old          0.982313\n",
      "uncle        0.981446\n",
      "gilman       0.980858\n",
      "men          0.980281\n",
      "innsmouth    0.975999\n",
      "Name: HPL, dtype: float64 \n",
      "\n",
      "token\n",
      "raymond    0.999724\n",
      "adrian     0.997323\n",
      "perdita    0.996773\n",
      "her        0.996530\n",
      "towards    0.993994\n",
      "love       0.992044\n",
      "my         0.990871\n",
      "idris      0.989987\n",
      "she        0.988781\n",
      "plague     0.987963\n",
      "Name: MWS, dtype: float64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# examine DataFrame by author\n",
    "for name in probs.columns:\n",
    "    print(probs[name].nlargest(10),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize + Random Forest = Experiment 1 (Split / Vectorize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tuning\n",
    "# pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('vect', TfidfVectorizer(binary=True, stop_words=None)),\n",
    "    ('rf', RandomForestClassifier(oob_score=True, \n",
    "                                  random_state=1234, \n",
    "                                  warm_start=True,\n",
    "                                  bootstrap=True))\n",
    "])\n",
    "\n",
    "# parameters (please note too many)\n",
    "parameters = dict(\n",
    "    rf__max_features = ['sqrt','log2'],\n",
    "    rf__criterion = [\"gini\", \"entropy\"],\n",
    "    rf__max_depth = [3, None],\n",
    "    rf__min_samples_split = sp_randint(2, 11),\n",
    "    rf__min_samples_leaf =  sp_randint(1, 11),\n",
    "    rf__n_estimators = [10, 25, 50, 75, 100, 125, 150, 175, 200],\n",
    "    vect__max_df = (0.5, 0.75, 1.0),\n",
    "    vect__ngram_range = [(1,1), (1,2), (1,3)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cv=5 academically proven as best fold, kept n_jobs (jobs running parallel)= 1, output time\n",
    "rand_search = RandomizedSearchCV(pipeline, \n",
    "                           parameters, \n",
    "                           n_jobs=1, \n",
    "                           cv=5\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['vect', 'rf']\n",
      "parameters:\n",
      "{'rf__criterion': ['gini', 'entropy'],\n",
      " 'rf__max_depth': [3, None],\n",
      " 'rf__max_features': ['sqrt', 'log2'],\n",
      " 'rf__min_samples_leaf': <scipy.stats._distn_infrastructure.rv_frozen object at 0x11176b9b0>,\n",
      " 'rf__min_samples_split': <scipy.stats._distn_infrastructure.rv_frozen object at 0x11176b710>,\n",
      " 'rf__n_estimators': [10, 25, 50, 75, 100, 125, 150, 175, 200],\n",
      " 'vect__max_df': (0.5, 0.75, 1.0),\n",
      " 'vect__ngram_range': [(...), (...), (...)]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:439: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:444: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:439: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:444: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:439: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:444: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:439: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:444: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:439: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:444: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:439: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:444: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:439: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:444: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:439: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:444: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:439: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:444: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:439: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:444: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 30s, sys: 16.2 s, total: 3min 46s\n",
      "Wall time: 3min 47s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise',\n",
       "          estimator=Pipeline(steps=[('vect', TfidfVectorizer(analyzer='word', binary=True, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "   ...stimators=10, n_jobs=1, oob_score=True, random_state=1234,\n",
       "            verbose=0, warm_start=True))]),\n",
       "          fit_params={}, iid=True, n_iter=10, n_jobs=1,\n",
       "          param_distributions={'rf__max_features': ['sqrt', 'log2'], 'rf__criterion': ['gini', 'entropy'], 'rf__max_depth': [3, None], 'rf__min_samples_split': <scipy.stats._distn_infrastructure.rv_frozen object at 0x11176b710>, 'rf__min_samples_leaf': <scipy.stats._distn_infrastructure.rv_frozen object at 0x11176b9b0>, 'rf__n_estimators': [10, 25, 50, 75, 100, 125, 150, 175, 200], 'vect__max_df': (0.5, 0.75, 1.0), 'vect__ngram_range': [(1, 1), (1, 2), (1, 3)]},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score=True, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit model for best parameters\n",
    "print(\"Performing grid search...\")\n",
    "print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
    "print(\"parameters:\")\n",
    "pprint(parameters, depth=2)\n",
    "\n",
    "%time rand_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.642\n",
      "Best parameters set:\n",
      "\trf__criterion: 'entropy'\n",
      "\trf__max_depth: None\n",
      "\trf__max_features: 'log2'\n",
      "\trf__min_samples_leaf: 2\n",
      "\trf__min_samples_split: 2\n",
      "\trf__n_estimators: 125\n",
      "\tvect__max_df: 0.5\n",
      "\tvect__ngram_range: (1, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"Best score: %0.3f\" % rand_search.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "\n",
    "best_parameters = rand_search.best_estimator_.get_params()\n",
    "\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import and instantiate CountVectorizer (with the default parameters)\n",
    "vect_C1 = TfidfVectorizer(max_df=0.5, \n",
    "                          ngram_range=(1,2), \n",
    "                          stop_words=None)\n",
    "\n",
    "# random forest classifier; please note this is NOT including parameters\n",
    "rf_C1 = RandomForestClassifier(oob_score=True, \n",
    "                               warm_start=True,\n",
    "                               max_depth=None,\n",
    "                               criterion='entropy',\n",
    "                               max_features='sqrt',\n",
    "                               min_samples_leaf=6,\n",
    "                               min_samples_split=4,\n",
    "                               n_estimators=175)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit & transform with vectorizer\n",
    "X_train_dtm = vect_C1.fit_transform(X_train)\n",
    "\n",
    "# transform test set\n",
    "X_test_dtm = vect_C1.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.85 s, sys: 344 ms, total: 9.19 s\n",
      "Wall time: 9.22 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=6,\n",
       "            min_samples_split=4, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=175, n_jobs=1, oob_score=True, random_state=None,\n",
       "            verbose=0, warm_start=True)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit with classifer\n",
    "%time rf_C1.fit(X_train_dtm,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predict with training class\n",
    "y_train_pred = rf_C1.predict(X_train_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predict with testing class\n",
    "y_test_pred = rf_C1.predict(X_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.74891037864342136"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy score, train\n",
    "metrics.accuracy_score(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.68702757916241064"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy score, test\n",
    "metrics.accuracy_score(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5692,   72,  161],\n",
       "       [1631, 2485,  110],\n",
       "       [1563,  150, 2820]])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion matrix, train\n",
    "metrics.confusion_matrix(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1870,   29,   76],\n",
       "       [ 717,  650,   42],\n",
       "       [ 620,   48,  843]])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print confusion matrix\n",
    "metrics.confusion_matrix(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        EAP       0.64      0.96      0.77      5925\n",
      "        HPL       0.92      0.59      0.72      4226\n",
      "        MWS       0.91      0.62      0.74      4533\n",
      "\n",
      "avg / total       0.80      0.75      0.74     14684\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification report, train\n",
    "print(metrics.classification_report(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        EAP       0.58      0.95      0.72      1975\n",
      "        HPL       0.89      0.46      0.61      1409\n",
      "        MWS       0.88      0.56      0.68      1511\n",
      "\n",
      "avg / total       0.76      0.69      0.68      4895\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification report, test\n",
    "print(metrics.classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.680400435849\n"
     ]
    }
   ],
   "source": [
    "# OOB Score\n",
    "print(rf_C1.oob_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# vocabulary (same as first trial)\n",
    "X_tokens = vect_C1.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feature importance\n",
    "tokens_rf = pd.DataFrame({'token':X_tokens, \n",
    "                          'metric':rf_C1.feature_importances_}).set_index('token')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token\n",
      "her        0.021132\n",
      "raymond    0.011684\n",
      "my         0.010527\n",
      "upon       0.010472\n",
      "is         0.010361\n",
      "on         0.009368\n",
      "though     0.007773\n",
      "old        0.007448\n",
      "love       0.006973\n",
      "perdita    0.006906\n",
      "Name: metric, dtype: float64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tokens_rf['metric'].nlargest(10),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize + Random Forest = Experiment 2 (Vectorize / Split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['vect', 'rf']\n",
      "parameters:\n",
      "{'rf__criterion': ['gini', 'entropy'],\n",
      " 'rf__max_depth': [3, None],\n",
      " 'rf__max_features': ['sqrt', 'log2'],\n",
      " 'rf__min_samples_leaf': <scipy.stats._distn_infrastructure.rv_frozen object at 0x11176b9b0>,\n",
      " 'rf__min_samples_split': <scipy.stats._distn_infrastructure.rv_frozen object at 0x11176b710>,\n",
      " 'rf__n_estimators': [10, 25, 50, 75, 100, 125, 150, 175, 200],\n",
      " 'vect__max_df': (0.5, 0.75, 1.0),\n",
      " 'vect__ngram_range': [(...), (...), (...)]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:439: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:444: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:439: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:444: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:439: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:444: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:439: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:444: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:439: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:444: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 40s, sys: 28.5 s, total: 5min 8s\n",
      "Wall time: 5min 9s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise',\n",
       "          estimator=Pipeline(steps=[('vect', TfidfVectorizer(analyzer='word', binary=True, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "   ...stimators=10, n_jobs=1, oob_score=True, random_state=1234,\n",
       "            verbose=0, warm_start=True))]),\n",
       "          fit_params={}, iid=True, n_iter=10, n_jobs=1,\n",
       "          param_distributions={'rf__max_features': ['sqrt', 'log2'], 'rf__criterion': ['gini', 'entropy'], 'rf__max_depth': [3, None], 'rf__min_samples_split': <scipy.stats._distn_infrastructure.rv_frozen object at 0x11176b710>, 'rf__min_samples_leaf': <scipy.stats._distn_infrastructure.rv_frozen object at 0x11176b9b0>, 'rf__n_estimators': [10, 25, 50, 75, 100, 125, 150, 175, 200], 'vect__max_df': (0.5, 0.75, 1.0), 'vect__ngram_range': [(1, 1), (1, 2), (1, 3)]},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score=True, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit model for best parameters\n",
    "print(\"Performing grid search...\")\n",
    "print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
    "print(\"parameters:\")\n",
    "pprint(parameters, depth=2)\n",
    "\n",
    "%time rand_search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.665\n",
      "Best parameters set:\n",
      "\trf__criterion: 'entropy'\n",
      "\trf__max_depth: None\n",
      "\trf__max_features: 'sqrt'\n",
      "\trf__min_samples_leaf: 9\n",
      "\trf__min_samples_split: 4\n",
      "\trf__n_estimators: 50\n",
      "\tvect__max_df: 0.5\n",
      "\tvect__ngram_range: (1, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"Best score: %0.3f\" % rand_search.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "\n",
    "best_parameters = rand_search.best_estimator_.get_params()\n",
    "\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import and instantiate CountVectorizer (with the default parameters)\n",
    "vect_C2 = TfidfVectorizer(max_df=1.0, \n",
    "                          ngram_range=(1,2),\n",
    "                          stop_words=stop_word)\n",
    "\n",
    "# random forest classifier; please note this is NOT including parameters\n",
    "rf_C2 = RandomForestClassifier(oob_score=True, \n",
    "                               warm_start=True,\n",
    "                               max_depth=None,\n",
    "                               criterion='gini',\n",
    "                               max_features='sqrt',\n",
    "                               min_samples_leaf=1,\n",
    "                               min_samples_split=7,\n",
    "                               n_estimators=75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit with vectorizer\n",
    "vect_C2.fit(X)\n",
    "\n",
    "# transform train set\n",
    "X_train_dtm = vect_C2.transform(X_train)\n",
    "\n",
    "# transform test set\n",
    "X_test_dtm = vect_C2.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 17s, sys: 411 ms, total: 4min 18s\n",
      "Wall time: 4min 18s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=7, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=75, n_jobs=1, oob_score=True, random_state=None,\n",
       "            verbose=0, warm_start=True)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit with training class\n",
    "%time rf_C2.fit(X_train_dtm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predict with training class\n",
    "y_train_pred = rf_C2.predict(X_train_dtm)\n",
    "\n",
    "# predict with testing class\n",
    "y_test_pred = rf_C2.predict(X_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99870607463906291"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy score, train\n",
    "metrics.accuracy_score(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.72339121552604702"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy score, test\n",
    "metrics.accuracy_score(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5922,    0,    3],\n",
       "       [   5, 4214,    7],\n",
       "       [   4,    0, 4529]])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy score, test\n",
    "metrics.confusion_matrix(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1784,   83,  108],\n",
       "       [ 489,  825,   95],\n",
       "       [ 495,   84,  932]])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy score, test\n",
    "metrics.confusion_matrix(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        EAP       1.00      1.00      1.00      5925\n",
      "        HPL       1.00      1.00      1.00      4226\n",
      "        MWS       1.00      1.00      1.00      4533\n",
      "\n",
      "avg / total       1.00      1.00      1.00     14684\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# accuracy score, test\n",
    "print(metrics.classification_report(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        EAP       0.64      0.90      0.75      1975\n",
      "        HPL       0.83      0.59      0.69      1409\n",
      "        MWS       0.82      0.62      0.70      1511\n",
      "\n",
      "avg / total       0.75      0.72      0.72      4895\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# accuracy score, test\n",
    "print(metrics.classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.718060473985\n"
     ]
    }
   ],
   "source": [
    "# OOB Score\n",
    "print(rf_C2.oob_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# vocabulary (same as first trial)\n",
    "X_tokens = vect_C2.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feature importance\n",
    "tokens_rf = pd.DataFrame({'token':X_tokens, \n",
    "                          'metric':rf_C2.feature_importances_}).set_index('token')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token\n",
      "upon       0.006144\n",
      "raymond    0.005534\n",
      "perdita    0.003854\n",
      "though     0.003818\n",
      "love       0.003631\n",
      "adrian     0.003392\n",
      "old        0.003087\n",
      "father     0.002661\n",
      "towards    0.002489\n",
      "life       0.002411\n",
      "Name: metric, dtype: float64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tokens_rf['metric'].nlargest(10),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
