{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sai: spooky author identification\n",
    "## analysis 4: feature importance (mini_test)\n",
    "\n",
    "## strategy\n",
    "This will reproduce the dataset provided the work done in the first two.  However, this will work with feature importance.  Feature importance says \"what are the most important and predictive features for each author\"?  Which words resonate with which author?\n",
    "\n",
    "## code\n",
    "### preliminaries\n",
    "This is the 'de facto' run, where it loads libraries and necessary modules to perform the analysis.  Afterwards, it will read a simple csv file into a dataframe called 'texts.'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# words = np.array(vectorizer.get_feature_names())\n",
    "\n",
    "# x = np.eye(xtest.shape[1])                    # identity matrix\n",
    "# probs = clf.predict_log_proba(x)[:, 0]        # logistics regression probability\n",
    "# ind = np.argsort(probs)                       # organizes words with probabilities\n",
    "\n",
    "# good_words = words[ind[:10]]\n",
    "# bad_words = words[ind[-10:]]\n",
    "\n",
    "# good_prob = probs[ind[:10]]\n",
    "# bad_prob = probs[ind[-10:]]\n",
    "\n",
    "# print(\"Good words\\t     P(fresh | word)\")\n",
    "# for w, p in zip(good_words, good_prob):\n",
    "#     print(\"{:>20}\".format(w), \"{:.2f}\".format(1 - np.exp(p)))\n",
    "    \n",
    "# print(\"Bad words\\t     P(fresh | word)\")\n",
    "# for w, p in zip(bad_words, bad_prob):\n",
    "#     print(\"{:>20}\".format(w), \"{:.2f}\".format(1 - np.exp(p)))`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# sklearn\n",
    "from sklearn.cross_validation import train_test_split             # cross-validation\n",
    "from sklearn.feature_extraction.text import CountVectorizer       # vectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB                     # classifier\n",
    "from sklearn.linear_model import LogisticRegression               # classifier\n",
    "from sklearn.model_selection import GridSearchCV                  # parameter tuning\n",
    "from sklearn.pipeline import Pipeline                             # pipeline\n",
    "from sklearn import metrics                                       # metrics\n",
    "\n",
    "\n",
    "# other modules\n",
    "from stop_words import get_stop_words\n",
    "from pprint import pprint\n",
    "\n",
    "# Read training texts: texts\n",
    "texts = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get stop words to eliminate unnecessary words\n",
    "stop_words = get_stop_words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# choose X and y\n",
    "X = texts.text\n",
    "y = texts.author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cross validation\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 1\n",
    "# vectorizer \n",
    "vect_A1 = CountVectorizer(binary=True, ngram_range=(1,2), stop_words=stop_words, max_df=0.5)\n",
    "\n",
    "# classifier\n",
    "nb_A1 = MultinomialNB(alpha=0.1)\n",
    "log_reg = LogisticRegression(C=2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit & transform with vectorizer\n",
    "X_train_dtm = vect_A1.fit_transform(X_train)\n",
    "\n",
    "# fit with classifer\n",
    "nb_A1.fit(X_train_dtm, y_train)\n",
    "\n",
    "# predict with classifier\n",
    "y_pred_train = nb_A1.predict(X_train_dtm)\n",
    "\n",
    "# transform with vectorizer, then predict with classifier\n",
    "X_test_dtm = vect_A1.transform(X_test)\n",
    "y_pred_test = nb_A1.predict(X_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit with classifer\n",
    "log_reg.fit(X_train_dtm, y_train)\n",
    "\n",
    "# predict with classifier\n",
    "y_pred_train = log_reg.predict(X_train_dtm)\n",
    "\n",
    "# transform with vectorizer, then predict with classifier\n",
    "X_test_dtm = vect_A1.transform(X_test)\n",
    "y_pred_test = log_reg.predict(X_test_dtm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Examine for Further Insight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "182939"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store vocabulary of X_train\n",
    "X_train_tokens = vect_A1.get_feature_names()\n",
    "len(X_train_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aaem', 'ab', 'ab te', 'aback', 'aback breeze', 'aback reading', 'abaft', 'abaft engine', 'abandon', 'abandon considered', 'abandon expedition', 'abandon four', 'abandon hope', 'abandon idea', 'abandon purpose', 'abandon quest', 'abandon search', 'abandon strangers', 'abandoned', 'abandoned abortion', 'abandoned ah', 'abandoned associates', 'abandoned attempts', 'abandoned barn', 'abandoned bitterness', 'abandoned characters', 'abandoned city', 'abandoned dilapidated', 'abandoned gold', 'abandoned granary', 'abandoned halls', 'abandoned house', 'abandoned implicitly', 'abandoned owners', 'abandoned party', 'abandoned pursuit', 'abandoned railway', 'abandoned uncomplaining', 'abandoned utterly', 'abandoned wharves', 'abandoned without', 'abandoning', 'abandoning legitimate', 'abandoning route', 'abandoning terror', 'abandonment', 'abandonment driven', 'abandonment forbidden', 'abandonment impulses', 'abaout']\n"
     ]
    }
   ],
   "source": [
    "# slice first 50 tokens\n",
    "print(X_train_tokens[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['zigzagged drunkenly', 'zigzagging', 'zigzagging along', 'zigzagging line', 'zimmer', 'zimmer bent', 'zimmer curious', 'zimmer undoubtedly', 'zit', 'zit still', 'zit zide', 'zobna', 'zobna advance', 'zodiac', 'zodiac question', 'zodiacal', 'zodiacal light', 'zokkar', 'zokkar olden', 'zone', 'zone former', 'zone running', 'zorry', 'zuro', 'zuro sate', 'ångstrom', 'ædile', 'ædile mother', 'ægyptus', 'ægyptus cryptic', 'æmilianus', 'æmilianus adds', 'æmilianus cornelius', 'æneid', 'æneid translation', 'ærial', 'ærial navigation', 'æronaut', 'æronaut appear', 'æronaut overhead', 'æronauts', 'æronauts mr', 'ærostation', 'æschylus', 'æschylus fifty', 'élite', 'élite city', 'οἶδα', 'οἶδα know', 'οἶδα οἶδα']\n"
     ]
    }
   ],
   "source": [
    "# slice first 50 tokens\n",
    "print(X_train_tokens[-50:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  1.,  1., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  1.,  1.,  1.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Naive Bayes counts the number of times each token appears in each class\n",
    "nb_A1.feature_count_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 182939)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rows represent classes\n",
    "nb_A1.feature_count_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# number of times each token appears across all HAM messages\n",
    "EAP_token_count = nb_A1.feature_count_[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of times each token appears across all SPAM messages\n",
    "HPL_token_count = nb_A1.feature_count_[1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "MWS_token_count = nb_A1.feature_count_[2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EAP</th>\n",
       "      <th>HPL</th>\n",
       "      <th>MWS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aaem</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ab</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ab te</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aback</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aback breeze</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              EAP  HPL  MWS\n",
       "token                      \n",
       "aaem          1.0  0.0  0.0\n",
       "ab            1.0  0.0  0.0\n",
       "ab te         1.0  0.0  0.0\n",
       "aback         2.0  0.0  0.0\n",
       "aback breeze  1.0  0.0  0.0"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DataFrame of tokens with their separate ham and spam counts\n",
    "tokens = pd.DataFrame({'token':X_train_tokens, 'EAP':EAP_token_count, 'HPL':HPL_token_count, 'MWS':MWS_token_count}).set_index('token')\n",
    "tokens.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EAP</th>\n",
       "      <th>HPL</th>\n",
       "      <th>MWS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>saying sleep</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tortured can</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>felt witnessed</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thus pampered</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forget tale</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                EAP  HPL  MWS\n",
       "token                        \n",
       "saying sleep    1.0  0.0  0.0\n",
       "tortured can    0.0  0.0  1.0\n",
       "felt witnessed  0.0  1.0  0.0\n",
       "thus pampered   0.0  0.0  1.0\n",
       "forget tale     0.0  0.0  1.0"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example 5 random DF rows\n",
    "tokens.sample(5, random_state=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5925.,  4226.,  4533.])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Naive Bayes counts the number of observations \n",
    "nb_A1.class_count_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EAP</th>\n",
       "      <th>HPL</th>\n",
       "      <th>MWS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>saying sleep</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tortured can</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>felt witnessed</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thus pampered</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forget tale</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                EAP  HPL  MWS\n",
       "token                        \n",
       "saying sleep    2.0  1.0  1.0\n",
       "tortured can    1.0  1.0  2.0\n",
       "felt witnessed  1.0  2.0  1.0\n",
       "thus pampered   1.0  1.0  2.0\n",
       "forget tale     1.0  1.0  2.0"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add 1 to ham and spam counts to avoid dividing by 0 (class imbalance)\n",
    "tokens['EAP'] = tokens.EAP + 1\n",
    "tokens['HPL'] = tokens.HPL + 1\n",
    "tokens['MWS'] = tokens.MWS + 1\n",
    "tokens.sample(5, random_state=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EAP</th>\n",
       "      <th>HPL</th>\n",
       "      <th>MWS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>saying sleep</th>\n",
       "      <td>0.000338</td>\n",
       "      <td>0.000237</td>\n",
       "      <td>0.000221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tortured can</th>\n",
       "      <td>0.000169</td>\n",
       "      <td>0.000237</td>\n",
       "      <td>0.000441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>felt witnessed</th>\n",
       "      <td>0.000169</td>\n",
       "      <td>0.000473</td>\n",
       "      <td>0.000221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thus pampered</th>\n",
       "      <td>0.000169</td>\n",
       "      <td>0.000237</td>\n",
       "      <td>0.000441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forget tale</th>\n",
       "      <td>0.000169</td>\n",
       "      <td>0.000237</td>\n",
       "      <td>0.000441</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     EAP       HPL       MWS\n",
       "token                                       \n",
       "saying sleep    0.000338  0.000237  0.000221\n",
       "tortured can    0.000169  0.000237  0.000441\n",
       "felt witnessed  0.000169  0.000473  0.000221\n",
       "thus pampered   0.000169  0.000237  0.000441\n",
       "forget tale     0.000169  0.000237  0.000441"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert ham and spam into frequencies \n",
    "tokens['EAP'] = tokens.EAP / nb_A1.class_count_[0]\n",
    "tokens['HPL'] = tokens.HPL / nb_A1.class_count_[1]\n",
    "tokens['MWS'] = tokens.MWS / nb_A1.class_count_[2]\n",
    "tokens.sample(5, random_state=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "token\n",
       "upon       0.113586\n",
       "one        0.072743\n",
       "now        0.057046\n",
       "will       0.047089\n",
       "said       0.043882\n",
       "little     0.033418\n",
       "even       0.033080\n",
       "say        0.032743\n",
       "well       0.032574\n",
       "however    0.032574\n",
       "Name: EAP, dtype: float64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine DataFrame sorted by spam_ratio\n",
    "# note: use sort() instead of sort_values() for pandas 0.16.2 and earlier\n",
    "tokens['EAP'].sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
