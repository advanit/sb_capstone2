{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sai: spooky author identification\n",
    "## analysis 2: refine simple practices\n",
    "\n",
    "## strategy\n",
    "The dataset is the training set.  The training set has three attributes: ID, author, and text class.  This is a multi-class text classification algorithm; this will determine the probability of who wrote which text based on the word usage and several machine learning algorithms.  \n",
    "\n",
    "The strategy is to use the training set and perform two experiments.  Before performing the experiments, parameter tuning would be performed beforehand to save time and execution.  After that the two experiments are shown below.\n",
    "\n",
    "The first experiment would include:\n",
    "\n",
    "* Feature selection (split)\n",
    "* Feature extraction (vectorize)\n",
    "* Classification processing (fit/predict)\n",
    "* Metrics (evaluate)\n",
    "* Identification (identify)\n",
    "\n",
    "Then the second experiment would include:\n",
    "\n",
    "* Feature extraction (vectorize)\n",
    "* Feature selection (split)\n",
    "* Classification processing (fit/predict)\n",
    "* Metrics (evaluate)\n",
    "* Identification (identify)\n",
    "\n",
    "Here, the first two are switch.  Vectorize the entire set and then perform classical machine learning.  This will be a good example.  \n",
    "\n",
    "For now, the algorithmss are:\n",
    "* vectorizer: CountVectorizer()\n",
    "* classification: Naive Bayes (MultinomialNB()), Logistic Regression (LogisticsRegression())\n",
    "\n",
    "\n",
    "| ALGORITHM | STEP | VECTORIZER | CLASSIFIER |\n",
    "|---|---|---|---|\n",
    "|1| A | CountVectorizer | MultinomialNB |\n",
    "|2| B | CountVectorizer | MultinomialNB |\n",
    "|3| A | CountVectorizer | LogisticRegression |\n",
    "|4| B | CountVectorizer | LogisticRegression |\n",
    "\n",
    "\n",
    "## code\n",
    "### preliminaries\n",
    "This is the 'de facto' run, where it loads libraries and necessary modules to perform the analysis.  Afterwards, it will read a simple csv file into a dataframe called 'texts.'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# sklearn\n",
    "from sklearn.cross_validation import train_test_split             # cross-validation\n",
    "from sklearn.feature_extraction.text import CountVectorizer       # vectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer      # vectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB                     # classifier\n",
    "from sklearn.linear_model import LogisticRegression               # classifier\n",
    "from sklearn.model_selection import GridSearchCV                  # parameter tuning\n",
    "from sklearn.pipeline import Pipeline                             # pipeline\n",
    "from sklearn import metrics                                       # metrics\n",
    "\n",
    "# other modules\n",
    "from stop_words import get_stop_words\n",
    "import string\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "# Read training texts: texts\n",
    "texts = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### exploratory data analysis\n",
    "This explores the dataset imported.  The first analysis is size by author, or how many observations per author.  Notice how EAP (Edgar Allen Poe) has the most while HPL (HP Lovecraft) had over 5,600.  But the spread was not substantial; the maximum difference between Poe's prose and Lovecraft's were about 2,265.  MWS (Mary W Shelley) was in the middle.  This also created an arbitrary attribute, length, which will not help with identification but does provide an idea of whose words will weigh the most and how influential the bulk will be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EAP    7900\n",
       "MWS    6044\n",
       "HPL    5635\n",
       "Name: author, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Texts per author\n",
    "texts.author.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">id</th>\n",
       "      <th colspan=\"4\" halign=\"left\">text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>author</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>EAP</th>\n",
       "      <td>7900</td>\n",
       "      <td>7900</td>\n",
       "      <td>id24058</td>\n",
       "      <td>1</td>\n",
       "      <td>7900</td>\n",
       "      <td>7900</td>\n",
       "      <td>In the street, next morning, my great, great, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HPL</th>\n",
       "      <td>5635</td>\n",
       "      <td>5635</td>\n",
       "      <td>id14804</td>\n",
       "      <td>1</td>\n",
       "      <td>5635</td>\n",
       "      <td>5635</td>\n",
       "      <td>Apparently it was a point somewhere between Hy...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MWS</th>\n",
       "      <td>6044</td>\n",
       "      <td>6044</td>\n",
       "      <td>id08278</td>\n",
       "      <td>1</td>\n",
       "      <td>6044</td>\n",
       "      <td>6044</td>\n",
       "      <td>Do you think that I will be questioned, and my...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                       text         \\\n",
       "       count unique      top freq count unique   \n",
       "author                                           \n",
       "EAP     7900   7900  id24058    1  7900   7900   \n",
       "HPL     5635   5635  id14804    1  5635   5635   \n",
       "MWS     6044   6044  id08278    1  6044   6044   \n",
       "\n",
       "                                                                \n",
       "                                                      top freq  \n",
       "author                                                          \n",
       "EAP     In the street, next morning, my great, great, ...    1  \n",
       "HPL     Apparently it was a point somewhere between Hy...    1  \n",
       "MWS     Do you think that I will be questioned, and my...    1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Texts size, test size\n",
    "texts.groupby('author').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id26305</td>\n",
       "      <td>This process, however, afforded me no means of...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id17569</td>\n",
       "      <td>It never once occurred to me that the fumbling...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id11008</td>\n",
       "      <td>In his left hand was a gold snuff box, from wh...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id27763</td>\n",
       "      <td>How lovely is spring As we looked from Windsor...</td>\n",
       "      <td>MWS</td>\n",
       "      <td>206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id12958</td>\n",
       "      <td>Finding nothing else, not even gold, the Super...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text author  length\n",
       "0  id26305  This process, however, afforded me no means of...    EAP     231\n",
       "1  id17569  It never once occurred to me that the fumbling...    HPL      71\n",
       "2  id11008  In his left hand was a gold snuff box, from wh...    EAP     200\n",
       "3  id27763  How lovely is spring As we looked from Windsor...    MWS     206\n",
       "4  id12958  Finding nothing else, not even gold, the Super...    HPL     174"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts['length'] = texts['text'].apply(len)\n",
    "texts.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    19579\n",
       "mean       149\n",
       "std        107\n",
       "min         21\n",
       "25%         81\n",
       "50%        128\n",
       "75%        191\n",
       "max       4663\n",
       "Name: length, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts.length.describe().apply(round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>author</th>\n",
       "      <th>EAP</th>\n",
       "      <th>HPL</th>\n",
       "      <th>MWS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7900.0</td>\n",
       "      <td>5635.0</td>\n",
       "      <td>6044.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>142.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>152.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>106.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>126.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>21.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>68.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>84.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>115.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>130.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>186.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>192.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1533.0</td>\n",
       "      <td>900.0</td>\n",
       "      <td>4663.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "author     EAP     HPL     MWS\n",
       "count   7900.0  5635.0  6044.0\n",
       "mean     142.0   156.0   152.0\n",
       "std      106.0    82.0   126.0\n",
       "min       21.0    21.0    21.0\n",
       "25%       68.0    98.0    84.0\n",
       "50%      115.0   142.0   130.0\n",
       "75%      186.0   196.0   192.0\n",
       "max     1533.0   900.0  4663.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts.groupby('author').length.describe().transpose().apply(round)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These length statistics may say little but still imply a lot.  All three will have text with no less than 21 words.  Also, 75% of the texts will contain about 190 words.  Between 75% and 100%, outliers will appear.  For instance, one of Mary Shelley's prose contains 4,663 words alone.  The histograms of the prose count by words is shown below, both as a total and by author.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x11e5bae48>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAD3CAYAAAAHQMOGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x111a01048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "texts['length'].plot(bins=50,kind = 'hist',range=[0,1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x11d862710>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x11a91bcc0>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x11a92de48>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x11a9eb940>]], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABKYAAAJVCAYAAADkyP1rAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n+D9UJBs8DNaV4QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11ddbe2b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot length by author\n",
    "texts.hist(column='length',by ='author',bins=50,figsize =(20,10),range=[0,1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## feature selection\n",
    "Because the categories are small, the target data X will be the text prose and the target response y is the author.  In other words, this will identify the author by looking at the words the author uses.  Advanced features such as sentiment and others will be based on hyperparamater tuning! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# choose X and y\n",
    "X = texts.text\n",
    "y = texts.author"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## experiment 1 split & vectorize\n",
    "The first method splits the training set between train and test data.  It will hold onto 70% for training.  First, it is important to tune the pipelines to see what would be the best combination for manipulating the data to get higher accuracy.  Two pipelines are performed: both with the same vectorizer but different classifiers.\n",
    "\n",
    "### tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import stop words to reduce noise\n",
    "stop_words = get_stop_words('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pipeline\n",
    "pipeline_A1 = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    #('tfidf', TfidfTransformer()),\n",
    "    ('nb', MultinomialNB()),\n",
    "])\n",
    "\n",
    "# parameters\n",
    "parameters_A1 = dict(\n",
    "    #vect__binary=[True, False], \n",
    "    vect__max_df = (0.5, 0.75, 1.0),\n",
    "    vect__ngram_range = [(1,1), (1,2), (1,3), (2,2), (2,3), (3,3)],\n",
    "    #vect__min_df=[0,1,2,3,4,5], # keep min_df default\n",
    "    nb__alpha = [0.05, 0.1, 1.0, 2.0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cv=5 academically proven as best fold, kept n_jobs (jobs running parallel)= 1, output time\n",
    "grid_search_A1 = GridSearchCV(pipeline_A1, \n",
    "                           parameters_A1, \n",
    "                           n_jobs=1, \n",
    "                           cv=5\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['vect', 'nb']\n",
      "parameters:\n",
      "{'nb__alpha': [0.05, 0.1, 1.0, 2.0],\n",
      " 'vect__max_df': (0.5, 0.75, 1.0),\n",
      " 'vect__ngram_range': [(...), (...), (...), (...), (...), (...)]}\n",
      "CPU times: user 15min 26s, sys: 23 s, total: 15min 49s\n",
      "Wall time: 15min 52s\n",
      "Best score: 0.846\n",
      "Best parameters set:\n",
      "\tnb__alpha: 0.1\n",
      "\tvect__max_df: 0.5\n",
      "\tvect__ngram_range: (1, 2)\n"
     ]
    }
   ],
   "source": [
    "# fit model for best parameters\n",
    "print(\"Performing grid search...\")\n",
    "print(\"pipeline:\", [name for name, _ in pipeline_A1.steps])\n",
    "print(\"parameters:\")\n",
    "pprint(parameters_A1, depth=2)\n",
    "\n",
    "%time grid_search_A1.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best score: %0.3f\" % grid_search_A1.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "\n",
    "best_parameters = grid_search_A1.best_estimator_.get_params()\n",
    "\n",
    "for param_name in sorted(parameters_A1.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pipeline\n",
    "pipeline_A2 = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    #('tfidf', TfidfTransformer()),\n",
    "    ('logreg', LogisticRegression()),\n",
    "])\n",
    "\n",
    "# parameters\n",
    "parameters_A2 = dict(\n",
    "    #vect__binary=[True, False], \n",
    "    vect__max_df = (0.5, 0.75, 1.0),\n",
    "    vect__ngram_range =  [(1,1), (1,2), (1,3), (2,2), (2,3), (3,3)],\n",
    "    #vect__min_df=[0,1,2,3,4,5], # keep min_df default\n",
    "    logreg__C = [0.05, 0.1, 1.0, 2.0], # positive float\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cv=5 academically proven as best fold, kept n_jobs (jobs running parallel)= 1, output time\n",
    "grid_search_A2 = GridSearchCV(pipeline_A2, \n",
    "                           parameters_A2, \n",
    "                           n_jobs=1, \n",
    "                           cv=5\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['vect', 'logreg']\n",
      "parameters:\n",
      "{'logreg__C': [0.05, 0.1, 1.0, 2.0],\n",
      " 'vect__max_df': (0.5, 0.75, 1.0),\n",
      " 'vect__ngram_range': [(...), (...), (...), (...), (...), (...)]}\n",
      "CPU times: user 41min 19s, sys: 50.4 s, total: 42min 9s\n",
      "Wall time: 22min 42s\n",
      "Best score: 0.812\n",
      "Best parameters set:\n",
      "\tlogreg__C: 1.0\n",
      "\tvect__max_df: 0.5\n",
      "\tvect__ngram_range: (1, 1)\n"
     ]
    }
   ],
   "source": [
    "# fit model to determine best parameters\n",
    "print(\"Performing grid search...\")\n",
    "print(\"pipeline:\", [name for name, _ in pipeline_A2.steps])\n",
    "print(\"parameters:\")\n",
    "pprint(parameters_A2, depth=2)\n",
    "\n",
    "%time grid_search_A2.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best score: %0.3f\" % grid_search_A2.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "\n",
    "best_parameters = grid_search_A2.best_estimator_.get_params()\n",
    "\n",
    "for param_name in sorted(parameters_A2.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split\n",
    "Here, the training and test data are split using a popular sklearn function, with stratification important to avoid biased data manipulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cross validation\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### vectorize\n",
    "This will use the CountVectorizer function with the hyperparameters provided.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline_1A = Pipeline([\n",
    "    ('vect', CountVectorizer(binary=True, ngram_range=(1,2), stop_words=None, max_df=0.5)),\n",
    "    #('tfidf', TfidfTransformer()),\n",
    "    ('nb', MultinomialNB(alpha=0.1))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fit and predict\n",
    "Using the pipeline, fit with the training data and then test with the performing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=True, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.5, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 2), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)), ('nb', MultinomialNB(alpha=0.1, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_1A.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred_train = pipeline_1A.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred_test = pipeline_1A.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluation\n",
    "Here, this will evaluate with three metrics: accuracy score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.997275946609\n"
     ]
    }
   ],
   "source": [
    "print(metrics.accuracy_score(y_pred_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8582226762\n"
     ]
    }
   ],
   "source": [
    "print(metrics.accuracy_score(y_pred_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5908    8    7]\n",
      " [   6 4211    1]\n",
      " [  11    7 4525]]\n"
     ]
    }
   ],
   "source": [
    "print(metrics.confusion_matrix(y_pred_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1664  130  122]\n",
      " [ 122 1202   54]\n",
      " [ 189   77 1335]]\n"
     ]
    }
   ],
   "source": [
    "print(metrics.confusion_matrix(y_pred_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        EAP       1.00      1.00      1.00      5923\n",
      "        HPL       1.00      1.00      1.00      4218\n",
      "        MWS       1.00      1.00      1.00      4543\n",
      "\n",
      "avg / total       1.00      1.00      1.00     14684\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_pred_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        EAP       0.84      0.87      0.86      1916\n",
      "        HPL       0.85      0.87      0.86      1378\n",
      "        MWS       0.88      0.83      0.86      1601\n",
      "\n",
      "avg / total       0.86      0.86      0.86      4895\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_pred_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "exp1_A_lst1 = pipeline_1A.predict_proba(X_test)\n",
    "exp1_A_lst2 = pipeline_1A.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_prob = pd.DataFrame(pipeline_1A.predict_proba(X_train), columns=['EAP','HPL','MWS'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### vectorize w/ LogisticRegression()\n",
    "This uses LogisticRegression() with the hyperparameter tuning mentioned above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline_1B = Pipeline([\n",
    "    ('vect', CountVectorizer(binary=True, ngram_range=(1,1), stop_words=None, max_df=0.75)),\n",
    "    #('tfidf', TfidfTransformer()),\n",
    "    ('logreg', LogisticRegression(C=1.0)),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fit and predict w/ LogisticRegression()\n",
    "Fit the training set, apply it on the test set, and create a prediction model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=True, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.75, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip...ty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_1B.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred_train = pipeline_1B.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred_test = pipeline_1B.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluation w/ LogisticRegression()\n",
    "Here, this will evaluate with three metrics: accuracy score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.970239716698\n"
     ]
    }
   ],
   "source": [
    "print(metrics.accuracy_score(y_pred_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.831664964249\n"
     ]
    }
   ],
   "source": [
    "print(metrics.accuracy_score(y_pred_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5815  113  166]\n",
      " [  37 4092   27]\n",
      " [  73   21 4340]]\n"
     ]
    }
   ],
   "source": [
    "print(metrics.confusion_matrix(y_pred_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1719  209  216]\n",
      " [ 114 1123   66]\n",
      " [ 142   77 1229]]\n"
     ]
    }
   ],
   "source": [
    "print(metrics.confusion_matrix(y_pred_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        EAP       0.98      0.95      0.97      6094\n",
      "        HPL       0.97      0.98      0.98      4156\n",
      "        MWS       0.96      0.98      0.97      4434\n",
      "\n",
      "avg / total       0.97      0.97      0.97     14684\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_pred_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        EAP       0.87      0.80      0.83      2144\n",
      "        HPL       0.80      0.86      0.83      1303\n",
      "        MWS       0.81      0.85      0.83      1448\n",
      "\n",
      "avg / total       0.83      0.83      0.83      4895\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_pred_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "exp1_A_lst3 = pipeline_1A.predict_proba(X_test)\n",
    "exp1_A_lst4 = pipeline_1A.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "## experiment 2 vectorize & split\n",
    "The second method takes the entire corpus and then splits the data.  Two pipelines are performed: both with the same vectorizer but different classifiers.\n",
    "\n",
    "### tune\n",
    "Like before, it will tune first.  Then it will apply it to fit and predict.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initiate the vectorizer\n",
    "pipeline_B1 = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('nb', MultinomialNB())\n",
    "])\n",
    "\n",
    "# parameters\n",
    "parameters_B1 = {\n",
    "    'vect__max_df': (0.5, 0.75, 1.0),\n",
    "    #'vect__max_features': (None, 5000, 10000, 50000),\n",
    "    'vect__ngram_range': ((1, 1), (1, 2), (2, 2)),  # unigrams or bigrams\n",
    "    'nb__alpha': [0.05, 0.1, 1.0, 2.0]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# gridsearch\n",
    "# cv=5 academically proven as best fold, kept n_jobs (jobs running parallel)= 1, output time\n",
    "grid_search_B1 = GridSearchCV(pipeline_B1, \n",
    "                           parameters_B1, \n",
    "                           n_jobs=1, \n",
    "                           cv=5\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['vect', 'nb']\n",
      "parameters:\n",
      "{'nb__alpha': [0.05, 0.1, 1.0, 2.0],\n",
      " 'vect__max_df': (0.5, 0.75, 1.0),\n",
      " 'vect__ngram_range': ((...), (...), (...))}\n",
      "CPU times: user 6min 58s, sys: 10.4 s, total: 7min 9s\n",
      "Wall time: 7min 11s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)), ('nb', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'vect__max_df': (0.5, 0.75, 1.0), 'vect__ngram_range': ((1, 1), (1, 2), (2, 2)), 'nb__alpha': [0.05, 0.1, 1.0, 2.0]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit model to determine best parameters\n",
    "print(\"Performing grid search...\")\n",
    "print(\"pipeline:\", [name for name, _ in pipeline_B1.steps])\n",
    "print(\"parameters:\")\n",
    "pprint(parameters_B1, depth=2)\n",
    "\n",
    "%time grid_search_B1.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.859\n",
      "Best parameters set:\n",
      "\tnb__alpha: 0.1\n",
      "\tvect__max_df: 0.5\n",
      "\tvect__ngram_range: (1, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"Best score: %0.3f\" % grid_search_B1.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "\n",
    "best_parameters = grid_search_B1.best_estimator_.get_params()\n",
    "\n",
    "for param_name in sorted(parameters_B1.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initiate the vectorizer\n",
    "pipeline_B2 = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('logreg', LogisticRegression())\n",
    "])\n",
    "\n",
    "# parameters\n",
    "parameters_B2 = {\n",
    "    'vect__max_df': (0.5, 0.75, 1.0),\n",
    "    #'vect__max_features': (None, 5000, 10000, 50000),\n",
    "    'vect__ngram_range': ((1, 1), (1, 2), (2, 2)),  # unigrams or bigrams\n",
    "    'logreg__C': [0.05, 0.1, 1.0, 2.0], # positive float\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cv=5 academically proven as best fold, kept n_jobs (jobs running parallel)= 1, output time\n",
    "grid_search_B2 = GridSearchCV(pipeline_B2, \n",
    "                           parameters_B2, \n",
    "                           n_jobs=1, \n",
    "                           cv=5\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['vect', 'logreg']\n",
      "parameters:\n",
      "{'logreg__C': [0.05, 0.1, 1.0, 2.0],\n",
      " 'vect__max_df': (0.5, 0.75, 1.0),\n",
      " 'vect__ngram_range': ((...), (...), (...))}\n",
      "CPU times: user 18min 58s, sys: 28.7 s, total: 19min 26s\n",
      "Wall time: 9min 31s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip...ty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))]),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'vect__max_df': (0.5, 0.75, 1.0), 'vect__ngram_range': ((1, 1), (1, 2), (2, 2)), 'logreg__C': [0.05, 0.1, 1.0, 2.0]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit model to determine best parameters\n",
    "print(\"Performing grid search...\")\n",
    "print(\"pipeline:\", [name for name, _ in pipeline_B2.steps])\n",
    "print(\"parameters:\")\n",
    "pprint(parameters_B2, depth=2)\n",
    "\n",
    "%time grid_search_B2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.810\n",
      "Best parameters set:\n",
      "\tlogreg__C: 1.0\n",
      "\tvect__max_df: 0.75\n",
      "\tvect__ngram_range: (1, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"Best score: %0.3f\" % grid_search_B2.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "\n",
    "best_parameters = grid_search_B2.best_estimator_.get_params()\n",
    "\n",
    "for param_name in sorted(parameters_B2.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import and instantiate CountVectorizer (with the default parameters)\n",
    "vect_B1 = CountVectorizer(max_df=0.5, ngram_range=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# learn the 'vocabulary' of the training data (occurs in-place)\n",
    "X_dtm = vect_B1.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cross validation\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fit & predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# transform \n",
    "X_train_dtm = vect_B1.transform(X_train)\n",
    "X_test_dtm = vect_B1.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set up Multinomial NB\n",
    "nb = MultinomialNB(alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.5, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit\n",
    "nb.fit(X_dtm, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predict with training class\n",
    "y_train_pred = nb.predict(X_train_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predict with testing class\n",
    "y_test_pred = nb.predict(X_test_dtm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9884908744211387"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy score, train\n",
    "metrics.accuracy_score(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99060265577119511"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy score, test\n",
    "metrics.accuracy_score(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5836,   26,   63],\n",
       "       [  28, 4180,   18],\n",
       "       [  28,    6, 4499]])"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion matrix, train\n",
    "metrics.confusion_matrix(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1955,    7,   13],\n",
       "       [   7, 1396,    6],\n",
       "       [   8,    5, 1498]])"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion matrix, test\n",
    "metrics.confusion_matrix(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        EAP       0.99      0.98      0.99      5925\n",
      "        HPL       0.99      0.99      0.99      4226\n",
      "        MWS       0.98      0.99      0.99      4533\n",
      "\n",
      "avg / total       0.99      0.99      0.99     14684\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification report, train\n",
    "print(metrics.classification_report(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        EAP       0.99      0.99      0.99      1975\n",
      "        HPL       0.99      0.99      0.99      1409\n",
      "        MWS       0.99      0.99      0.99      1511\n",
      "\n",
      "avg / total       0.99      0.99      0.99      4895\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification report, test\n",
    "print(metrics.classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate predicted probabilities for X_test_dtm\n",
    "# naive bayes = good classifier but bad something (not produced well-predicted probabilities)\n",
    "exp1_B_lst1 = nb.predict_proba(X_test_dtm)\n",
    "exp1_B_lst2 = nb.predict(X_test_dtm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### vectorize\n",
    "This will use the parameters that best maximize the accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import and instantiate CountVectorizer (with the default parameters)\n",
    "vect_B2 = CountVectorizer(max_df=0.75, ngram_range=(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_dtm = vect_B2.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split\n",
    "The split is the same; the training data will be used to evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cross validation\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fit & predict w/ LogisticRegression()\n",
    "This will keep the vectorization and split the same.  However, it will use LogisticRegression() over MultinomialNB().  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# transform \n",
    "X_train_dtm = vect_B2.transform(X_train)\n",
    "X_test_dtm = vect_B2.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(C=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.fit(X_dtm, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predict with training class\n",
    "y_train_pred = logreg.predict(X_train_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predict with testing class\n",
    "y_test_pred = logreg.predict(X_test_dtm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96806047398529016"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy score, train\n",
    "metrics.accuracy_score(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96894790602655767"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy score, test\n",
    "metrics.accuracy_score(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5800,   35,   90],\n",
       "       [ 116, 4086,   24],\n",
       "       [ 170,   34, 4329]])"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion matrix, train\n",
    "metrics.confusion_matrix(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1939,   17,   19],\n",
       "       [  35, 1361,   13],\n",
       "       [  58,   10, 1443]])"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print confusion matrix\n",
    "metrics.confusion_matrix(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        EAP       0.95      0.98      0.97      5925\n",
      "        HPL       0.98      0.97      0.98      4226\n",
      "        MWS       0.97      0.95      0.96      4533\n",
      "\n",
      "avg / total       0.97      0.97      0.97     14684\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification report, train\n",
    "print(metrics.classification_report(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        EAP       0.95      0.98      0.97      1975\n",
      "        HPL       0.98      0.97      0.97      1409\n",
      "        MWS       0.98      0.95      0.97      1511\n",
      "\n",
      "avg / total       0.97      0.97      0.97      4895\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification report, test\n",
    "print(metrics.classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate predicted probabilities for X_test_dtm\n",
    "# naive bayes = good classifier but bad something (not produced well-predicted probabilities)\n",
    "y_pred_prob = logreg.predict_proba(X_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate predicted probabilities for X_test_dtm\n",
    "# naive bayes = good classifier but bad something (not produced well-predicted probabilities)\n",
    "exp1_B_lst3 = logreg.predict_proba(X_test_dtm)\n",
    "exp1_B_lst4 = logreg.predict(X_test_dtm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
